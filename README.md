# ğŸ¤– AInotator: Annotate Utterance with AI

LLMs are rapidly catching up â€” but can they understand what is meant, not just what is said?
**AInotator** puts this question to the test. 
It is a lightweight but powerful framework for **automated utterance-level annotation** in **computer-mediated communication (CMC)**, powered by OpenAI models.

Given an Excel sheet of utterances with conversational context, the system applies a linguistically grounded schema to assign:

- **Communicative Act Labels** (e.g., Accept, Request, Reject)
- **Politeness Tags** following Herring (1994) and Culpeper (2011a)
- **Meta-Acts** (e.g., [non-bona fide], [reported])

Annotations are generated through structured prompting and saved in a reproducible, debuggable format. The tool supports:

- Resumable runs with progress logging
- Chain-of-thought (CoT) reasoning mode
- Reproducibility through fixed seeds and audit logs

## ğŸ§­ Annotation Schema

The model follows a taxonomy adapted from CMC pragmatics and politeness theory. Below is a summary of the categories used during annotation:

### ğŸ™ï¸ Communicative Act Labels

| Label          | Example                                                              |
|----------------|----------------------------------------------------------------------|
| Accept         | â€œExactly this.â€                                                      |
| Apologize      | â€œSorry this happened to your family.â€                                |
| Claim          | â€œI do not understand the mentality of people who...â€                 |
| Desire         | â€œI wish theyâ€™d just play the game together.â€                         |
| Direct         | â€œYou should try something else.â€                                     |
| Elaborate      | â€œThis isnâ€™t the first time it happened...â€                           |
| Inform         | â€œI recently played Terraria with friends...â€                         |
| Inquire        | â€œWhatâ€™s up with people being upset about this?â€                      |
| Invite         | â€œYou might want to post this in another subreddit.â€                  |
| React          | â€œLmao this is so dramatic.â€                                          |
| Reject         | â€œDude! You came here for answers and you are NOT listening.â€         |
| Request        | â€œCan someone explain this to me?â€                                    |
| Thank          | â€œThanks for saying this.â€                                            |

*(Less common labels like Behave, Greet, Manage, Repair are included but rarely observed.)*

### ğŸª Politeness & Impoliteness (Herring, 1994; Culpeper, 2011a)

| Code      | Meaning                                     | Examples                                        |
|-----------|---------------------------------------------|-------------------------------------------------|
| +P        | Positive politeness                         | Compliments, friendly joking                   |
| +N        | Negative politeness                         | Hedging, deference, giving options             |
| â€“P        | Violation of positive politeness            | Sarcasm, insults, mocking                      |
| â€“N        | Violation of negative politeness            | Commands, strong obligations, intrusive Qs     |

Impoliteness subtypes (e.g., `â€“P [Insult]`, `â€“P [Dismissal]`) are derived from Culpeper's framework.

### ğŸ·ï¸ Meta-Acts

| Tag            | Description                                         |
|----------------|-----------------------------------------------------|
| [non-bona fide] | Sarcasm, jokes, rhetorical questions                |
| [reported]      | Quoting or paraphrasing othersâ€™ speech or thoughts  |

---

## ğŸš€ Usage

```bash
python run.py 
python run.py --cot  # for reasoning
```

## ğŸ“‚ Output

Results are saved under `annotations/seed_<SEED>[_cot]/`:

- `annot_raw.parquet`: full prompt/response logs
- `annot_clean.csv`: parsed annotations only
- `annot_seq.csv`: aligned with the original Excel input

## ğŸ’¡ Why It Matters

Manual annotation of online discourse is slow, inconsistent, and hard to scale.

AInotator offers a practical, theory-aware solution â€” making it ideal for CMC researchers studying stance, identity, politeness, conflict, and solidarity at scale.

> LLMs may be changing the game â€” but we still define the rules.
 
## ğŸ› ï¸ Contributions
Contributions are welcome! Feel free to open an issue or submit a pull request.

## ğŸ“œ Version History

- **v0.0.3**  
  Adopted Susan's new [instruction](https://homes.luddy.indiana.edu/herring/cmc.acts.html#:~:text=The%20CMC%20Act%20Taxonomy%20is,acts%20in%20computer%2Dmediated%20discourse)

- **v0.0.2**  
  Enhanced prompt context with:
  - Background summary of the original Reddit post  
  - Inclusion of all thread-starting messages (Msg# == 1)  
  - Local conversational context (previous, target, next messages)  
  - Speaker metadata (User ID, gender, time, utterance ID)  
  Improved format validation and annotation reproducibility.

- **v0.0.1**  
  Initial prototype with support for communicative act classification, politeness/impoliteness tags, and meta-acts. Included CoT reasoning toggle and resumable run logic.


